## 第5章：隐马尔可夫模型

>拥有无限的想象空间才会有无限的未来。

- 1.复杂的语音识别问题居然能如此简单地表述、解决，令我由衷地感叹数学模型之妙。 --摘抄

> 作者认为数学的魅力在于可以将复杂的问题简单化，然而数学的魅力并不只是如此。

- 2.概率论

- 3.动态规划，维比特算法，鲍姆 - 韦尔奇算法，上帝的算法

- 4.鲍姆 - 韦尔奇算法的每一次迭代都是不断地估计新的模型参数，使得输出的概率（我们的目标函数）达到最大化，因此这个过程被称为期望值最大化，简称EM过程。 --摘抄

>每一次迭代都拿到一个最优解，那这是不是就是贪心算法的思想呢？

- 5.隐马尔可夫模型 + 鲍姆 - 韦尔奇算法 + 维特比算法

## 第6章：信息的度量和作用

- 1.我们常常说信息很多，或者信息较少，但却很难说清楚信息到底有多少。 --摘抄

>类似于度量算法的性能，时间复杂度和空间复杂度。

- 2.直到1948年，香农在他著名的论文“通信的数学原理”中提出了“信息熵”的概念，才解决了信息的度量问题，并且量化出信息的作用。

>量化一件事物的数据很重要，因为量化后的数据能让别人直接看见，这样才有说服力。

- 3.用一个猜世界杯冠军的例子尝试度量信息的价值。

- 4.用猜世界杯冠军的例子解释信息熵真的非常好，清晰易懂，这就是斯科特·杨文章里提到的比喻的力量，真的让人以看就懂了，不是那种晦涩专业的词语去解释，费曼学习法。

- 5.信息量的量化度量为什么叫作“熵”这么一个奇怪的名字呢？

- 6.算法某种意义上就是数学将问题简单化的一种手段。

- 7.一个txt文件的大小能不能作为信息的度量呢，txt文件的大小为什么是用M做单位呢？

- 8.我们知道情报的作用就是排除不确定性。

- 9.有些时候，在战争中1比特的信息能抵过千军万马。 --摘抄

>现实中也一样，所以有人可以通过信息差挣钱，所以我们需要对我们有益的获取信息的渠道，这也非常重要。

>每个人都有他的优点，所以善于挖掘别人或自己的优点加以运用，将获得巨大的收获。

- 10.几乎所有的自然语言处理、信息与信号处理的应用都是一个消除不确定性的过程。 --摘抄

>所以概率论和数理统计在这个领域就大放异彩。

- 11.合理利用信息，而非玩弄什么公式和机器学习算法，是做好搜索的关键。 --摘抄

>不忘初心方得始终。

- 12.在数学上可以严格地证明为什么这些“相关的”信息也能够消除不确定性。 --摘抄

>任何事情和方法都是有原理的，有据可循的，而不是靠“懵”的，懵是不行的，得相信科学。

- 总结：书中所说的数学之美，这个美美在哪？语音识别的数学基础是什么？如何度量信息？量化事物的数据是不是很重要？搜索的关键是什么？如何消除不确定性？

>数学之美的这个美美在能将复杂的问题变得简单。能将复杂的问题简单化。

>语音识别的数学基础是概率论和数理统计。

>用熵度量信息，推测包括今天的MB，可能也是从这来的。

>量化数据很重要，因为这能让人一眼就看到你的成果，非常的清晰明了。

>搜索的关键是利用好信息，而不是玩弄什么公式和机器学习的算法。不要手上有锤子，看什么都是钉子。

>通过一些数学的方法概率论，数理统计的只是加上一些前人的探索，一步步的消除不确定性。
