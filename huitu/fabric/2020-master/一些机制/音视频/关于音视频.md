## 视频如何展示

### 视频帧
简单介绍一下帧间压缩，以这个视频画面为例，视频以一连串的的画面组成，但是并不是每个画面都是有价值的，有可能有重复的关键帧，这个时候通过一定的视频算法去提取相应的关键帧，从而大大降低视频的大小。  
通过运动补偿将先前的局部图像来预测、补偿当前的局部图像，减少帧序列冗余信息；不同区域的图像则使用不同的运动矢量来描述运动信息，通过上述手段，以各种关键帧 + 预测帧实现去除空间上的冗余信息，这种就称为帧间压缩技术，其中衍生出来的视频帧就包括I、P、B帧。

#### I帧：帧内编码帧（intra picture）
I帧通常是每个GOP（MPEG所使用的一种视频压缩技术）的第一帧，经过适度地压缩，作为随机访问的参考点可以当成静态图像。I帧可以看做一个图像经过压缩后觉得产物，I帧压缩可以得6：1的压缩比而不会产生任何可觉察的模糊现象。I帧压缩可去掉视频的空间冗余信息。

#### P帧：前向预测编码帧（predictive-frame）
需要参考前面的I帧才能进行编码，表示的是当前帧画面与前一帧（前一帧可能是I帧也可能是P帧）的差别。解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。与I帧相比，P帧通常占用更少的数据位。

#### B帧：双向预测内插编码帧（bi-directionalinterpolated prediction frame）
B帧记录的是本帧与前后帧的差别，也就是说要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是对解码性能要求较高。

#### GOP：Group of Pictures
GOP是一组连续的画面，由一张 I 帧和数张 B / P 帧组成，是视频图像编码器和解码器存取的基本单位，它的排列顺序将会一直重复到影像结束。编码器将多张图像进行编码后生产成一段一段的 GOP ( Group of Pictures ) ， 解码器在播放时则是读取一段一段的 GOP 进行解码后读取画面再渲染显示。

### 时间戳 PTS & DTS
由于上面视频帧，衍生出以下概念：
- PTS （Presenting Time Stamp），帧播放时间戳。
- DTS （Decoding Time Stamp），帧解码时间戳。
在没有B帧的情况下，视频DTS和PTS的输出顺序是一样的。同理，音频的DTS和PTS也是一样的。因为B帧打乱了解码和显示的顺序，所以一旦存在B帧，PTS和DTS势必就会不同。FFmpeg中使用AVPacket结构体描述解码前或解码后的压缩数据，用AVFrame结构体来描述解码后或编码前的原始数据。对于视频来说，AVFrame就是视频的一帧图像，这帧图像什么时候给用户，取决于它的PTS。DTS是AVPacket里的一个成员，表示该压缩包应该什么时候被解压，如果视频里各帧里编码是按照输入顺序（显示顺序）依次进行的，那么解码和显示的时间应该是一致的。  
比如如下面这个视频，帧的DTS（视频帧通常以DTS的顺序来存储）顺序是：I P B B P B B，因为B帧解码需要依赖P帧，因此这几帧在视频流中的PTS顺序可能是：I B B P B B P。DTS 告诉我们该按什么顺序解码这几帧图像，PTS 告诉我们该按什么顺序显示这几帧图像。

### 音视频同步策略
一个AAC音频frame每个声道包含1024个采样点，则一个frame的播放时长(duration)为：(1024/44100)×1000ms = 23.22ms；一个H264视频frame播放时长(duration)为：1000ms/25 = 40ms。声卡虽然是以音频采样点为播放单位，但通常我们每次往声卡缓冲区送一个音频frame，每送一个音频frame更新一下音频的播放时刻，即每隔一个音频frame时长更新一下音频时钟。我们暂且把一个音频时钟更新点记作其播放点，理想情况下，音视频完全同步，音视频播放过程如下图所示：

### 参考时钟
实现音视频同步，在播放时，需要选定一个参考时钟，读取帧上的时间戳，同时根据的参考时钟来动态调节播放。现在已经知道时间戳就是PTS，那么参考时钟的选择一般来说有以下三种：
- 将视频同步到音频上：就是以音频的播放速度为基准来同步视频。
- 将音频同步到视频上：就是以视频的播放速度为基准来同步音频。
- 将视频和音频同步外部的时钟上：选择一个外部时钟为基准，视频和音频的播放速度都以该时钟为标准。
但是从现实的角度出发，人对于延迟-100ms ~ +90ms的视频画面并不敏感，而对于的音频就相当的敏感。如果以视频的播放速度为基准同步音频，在同步过程会导致音频的速度频繁的降低/加快，会带来比较差的视听感受，**一般播放器都会采用将视频同步到音频的同步策略**，后面就以ffplay的源码来剖析一下如何实现音视频同步。

### ffplay中的音视频同步
```js
main() => event_loop() => refresh_loop_wait_event() => video_refresh()
```
video_refresh的主体流程分为3个步骤：
1. 计算上一帧应显示的时长，判断是否继续显示上一帧
2. 估算当前帧应显示的时长，判断是否要丢帧
3. 调用video_display进行显示