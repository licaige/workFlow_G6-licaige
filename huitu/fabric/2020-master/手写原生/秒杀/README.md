https://blog.csdn.net/liangkaiping0525/article/details/80836104?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-0&spm=1001.2101.3001.4242

## 海量数据如何存储与快速查找
链表 查找太慢
hashMap 数组+链表  占用空间太大

位图：bitmap
优点：缩小空间、定位数据快、天然有序
缺点：数组下标只能是数字、并且随着下标越大空间越大如果数组稀疏
布隆过滤器：
1、把 url、name 通过多个 hash 存入 bitmap，hash 函数越多碰撞率越低，但只能趋近于 0
2、存在的不一定存在，不存在的一定不存在
如何减少误判率：增大布隆过滤器长度、增加 hash
那如何删除呢：
可以用计数器，但是就增加了空间、时间，舍本逐末，所以布隆过滤器不考虑删除
应用场景：
url 黑名单校验，冲突就二次校验
url 是否被爬虫爬过
618期间（短频快）可以用 redis-bloom 版本 bf.add

为了将数据项添加到布隆过滤器中，我们会提供 K 个不同的哈希函数，并将结果位置上对应位的值置为 “1”。在前面所提到的哈希表中，我们使用的是单个哈希函数，因此只能输出单个索引值。而对于布隆过滤器来说，我们将使用多个哈希函数，这将会产生多个索引值。

网页爬虫对 URL 去重，避免爬取相同的 URL 地址；
反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱；
Google Chrome 使用布隆过滤器识别恶意 URL；
Medium 使用布隆过滤器避免推荐给用户已经读过的文章；

## redis 为什么快
单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，其他模块仍用了多个线程。
单线程只是针对redis中的模块来说 比如 接受请求和响应是单线程，处理事件也是单线程 。但是线程不是同一个
https://zhuanlan.zhihu.com/p/52600663
1.redis是基于内存的，内存的读写速度非常快；
2.redis是单线程的，省去了很多上下文切换线程的时间；
3.非阻塞IO--redis使用多路复用技术，可以处理并发的连接。非阻塞IO 内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间。

redis支持string， list， set，sorted set，hash table 5种数据结构。
字符串，链表，集合，有序集合，哈希表

优点：
(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)
(2) 支持丰富数据类型，支持string，list，set，sorted set，hash
(3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行
(4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除

## 秒杀产生的问题
流量大、库存少、时间固定、不能超买超卖重买、限购、黄牛、读多写少
1、负载均衡，分而治之。通过负载均衡，将不同的流量划分到不同的机器上，每台机器处理好自己的请求，将自己的性能发挥到极致，这样系统的整体也就能承受极高的并发了，就像工作的的一个团队，每个人都将自己的价值发挥到了极致，团队成长自然是很大的。
2、合理的使用并发和异步。自epoll网络架构模型解决了c10k问题以来，异步越来被服务端开发人员所接受，能够用异步来做的工作，就用异步来做，在功能拆解上能达到意想不到的效果，这点在nginx、node.js、redis上都能体现，他们处理网络请求使用的epoll模型，用实践告诉了我们单线程依然可以发挥强大的威力。服务器已经进入了多核时代，go语言这种天生为并发而生的语言，完美的发挥了服务器多核优势，很多可以并发处理的任务都可以使用并发来解决，比如go处理http请求时每个请求都会在一个goroutine中执行，总之:怎样合理的压榨CPU,让其发挥出应有的价值，是我们一直需要探索学习的方向。

## 面试回答
https://zhuanlan.zhihu.com/p/92563050
https://www.pianshen.com/article/93191668727/
限流
缓存
库存数据一致性
    业界最为常见的是预扣库存。无论是外卖点餐还是电商购物，下单后一般都有个 “有效付款时间”，超过该时间订单自动释放，这就是典型的预扣库存方案

## 措施
1、限流：
    鉴于只有少部分用户能够秒杀成功，所以要限制大部分流量，只允许少部分流量进入服务后端。
2、削峰：
    高峰值流量是压垮系统很重要的原因，所以如何把瞬间的高流量变成一段时间平稳的流量也是设计秒杀系统很重要的思路。实现削峰的常用的方法有利用缓存和消息中间件等技术。
3、异步处理：
    秒杀系统是一个高并发系统，采用异步处理模式可以极大地提高系统并发量，
4、内存缓存：
    秒杀系统最大的瓶颈一般都是数据库读写，由于数据库读写属于磁盘IO，性能很低，如果能够把部分数据或业务逻辑转移到内存缓存，效率会有极大地提升。充分利用缓存，利用缓存可极大提高系统读写速度。
5、加机子

## 解决方案
事务时间要尽可能短
把被用户大量访问的静态资源缓存在CDN中
合理使用nosql缓存数据库
      使用这种方法的好处就是一致性维护成本低：请求地址要求拿到高并发接口的数据的时候，先访问服务器端缓存，若没有再访问数据库。如果高并发接口的数据需要改变的时候，我们可以等待缓存超时再更新数据，或者直接穿透到数据库更新，又或者当数据库数据更新的时候主动更新一下缓存。
脚本合理控制请求
使用具有高并发能力的编程语言去开发
      比如要统计用户通过各种方式(如点击图片/链接)进入到商品详情的行为次数，如果同时有1w个用户同时在线访问页面，一次拉动滚动条屏幕页面展示10件商品，这样就会有10w个请求过来，服务端需要把请求的次数数据入库，这样服务器分分钟给跪了。
        要解决这些访问量大的数据统计接口的问题，我们可以通过nodejs写一个数据处理接口，把统计数据先存到redis的list中，然后再使用nodejs写一个脚本，脚本的功能就是从redis里取出数据保存到mysql数据库中。这个脚本会一直运行，当redis没有数据需求要同步到数据库中的时候，sleep，然后再进行数据同步操作。
集群
  集群是一种多服务器结构，也就是把同一个业务，部署在多个服务器上(区别于分布式，分布式是把个业务分拆多个子业务，部署在不同的服务器上)，这样就可以提高单位时间内执行的任务数来提升效率，把压力分担到多台服务器上。
  我们可以集群部署Mysql数据库，或者NoSQL DB服务器(如mongodb服务器、redis服务器)，把一些常用的查询数据，并且不会经常变化的数据保存到NoSQL DB服务器，来减少数据库服务器的压力，加快数据的响应速度。





## 内核 kernal 其实也是个程序
app 里面的线程都需要经由 操作系统 OS 来调度去哪个 cpu，而 cpu 并不知道是哪个线程，只管执行。
线程切换，cpu 会将上一个线程保存到 cache 里，要保存现场（执行新线程，恢复现场）

## 一般一个 cpu 对应一个线程
但线程不是越多越好，线程在一个 cpu 中切换需要消耗资源（需要把线程1的存起来拿出去，再把线程2的数据拿进来运行）
实际工作中根据压测来定一个 CPU 跑多少个线程

## 既然是多线程就会有锁的问题
锁的本质就是在一个对象上的最终二进制的头部加上锁标识（object header）
synchronized(o) { // 同步锁、本质是悲观锁（虽然没人跟我抢，我也得加锁，就没必要）
  ....
}
所谓的锁定 o 就是修改 o 的头，记录锁信息
加锁之后并行就变成了序列化执行，又叫互斥锁

## mysql 单机并发量就 1000，redis 单机十万并发量，压测六七万
redis 单线程、高并发读写

## 什么时候把库存写入 redis
秒杀活动创建和维护时写入 redis

## 分库分表
防止一个数据库挂了，整个挂了

## 悲观锁
先锁后操作，多人就得等前面的锁释放，耗尽 mySql 的线程
数据量小、数据一致性、正确性要求高

## 乐观锁
不锁，更新失败才重新获取一下。不适用秒杀系统
里面的版本号就是一个 flag

CAS:CompareAndSet（swap），先读取，再比较，后设置。有 bug（比如经过多次修改又改回成原来的值） 所以得另外加一个字段，记录版本或类型


## 雪崩
当微服务A调用微服务B，B调用C和其他微服务，当调用链上某个服务不可用或响应时间过长，网关路由到A上的请求就会占用越来越多的系统资源，导致系统崩溃，这种现象称作雪崩效应。

## 熔断
只需要引入框架，设置 callback 函数到某个页面即可。
在分布式环境下，微服务之间不可避免的发生互相调用的情况，但是没有一个系统是能保证自身绝对正确的，在服务的调用过程中，很可能面临服务失败的问题，因此需要一个公共组件能够在服务通过网络请求访问其他微服务时，能对服务失效情况下有很强的容错能力，对微服务提供保护和监控。
他能够在依赖服务失效的情况下，通过隔离系统依赖的方式，防止服务的级联失败(服务的雪崩)
一般是某个服务故障或者是异常引起的，类似于“保险丝”，当某个异常条件被触发，为了防止服务雪崩，直接熔断服务，而不是一直等到此服务超时。
典型的熔断场景：例如过载保护，当请求线程数过多时被限流，


## 服务降级
当服务器压力剧增时，根据当前业务情况及流量，对一些非核心服务进行有策略的停服，缓解服务器资源压力，以保证核心业务的正常运行。
自动降级：超时、失败次数过多、故障
响应时间超过配置的超时时间（异步机制探测回复情况）
不稳的API调用次数达到一定数量（异步机制探测回复情况）
调用的服务出现故障（HTTP状态码、网络故障、RPC服务异常）
人工降级：秒杀、双十一大促，非核心服务停服


## 熔断和降级异同
相同点
从可用性和可靠性触发，为了防止系统崩溃
最终让用户体验到的是某些功能暂时不能用
不同点
服务熔断一般是下游服务故障导致的
服务降级一般是从整体系统负荷考虑，由调用方控制



## 进程和线程
不错的文章 https://www.rrfed.com/2017/05/21/js-threads/
由于四核四线程的CPU同一时间只能运行四个线程，所以有些线程会处于运行状态，而大部份的线程会处理于中断、堵塞、睡眠的状态，所以这里就涉及到操作系统的任务调度。
一个CPU有几个核它就可以跑多少个线程，四核四线程就说明这个CPU同一时间最多能够运行4个线程，四核八线程是使用了超线程技术，使得单个核像有两个核一样，速度比四核四线程有所提升。但是当你看你电脑的任务管理器，你会发现实际上会运行几千个线程，如下图当前OS运行了1917个线程，376个进程（进程是线程的容器，每个进程至少有一个主线程）。
由于四核四线程的CPU同一时间只能运行四个线程，所以有些线程会处于运行状态，而大部份的线程会处理于中断、堵塞、睡眠的状态，所以这里就涉及到操作系统的任务调度。

同一进程的线程共享那些资源：
- 堆
- 全局变量
- 文件
